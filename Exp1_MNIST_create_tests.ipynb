{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/as791/Adversarial-Example-Attack-and-Defense/blob/master/Adversarial_Example_(Attack_and_defense).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aGrkQarm97Ye",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import os\n",
    "from torchvision import transforms,datasets\n",
    "from torch.autograd import Variable\n",
    "import copy\n",
    "from torch.autograd.gradcheck import zero_gradients\n",
    "from scipy import optimize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "0Rt-4inOweid",
    "outputId": "8b301031-02dd-4473-b45a-71b2564b9915",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x25dc6af1210>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GkxWvr7aviFj",
    "tags": []
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.0,), (1.0,))])\n",
    "dataset = datasets.MNIST(root = './data', train=True, transform = transform, download=True)\n",
    "train_set, val_set = torch.utils.data.random_split(dataset, [50000, 10000])\n",
    "test_set = datasets.MNIST(root = './data', train=False, transform = transform, download=True)\n",
    "train_loader = torch.utils.data.DataLoader(train_set,batch_size=128,shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_set,batch_size=128,shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_set,batch_size=1,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "XVMI7iDTmarW",
    "outputId": "6b3ed0fd-2eda-4615-a6a0-1f8ebf031496",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: 391 Validation data: 79 Test data:  10000\n"
     ]
    }
   ],
   "source": [
    "print(\"Training data:\",len(train_loader),\"Validation data:\",len(val_loader),\"Test data: \",len(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pknHQZaMYpwC",
    "tags": []
   },
   "outputs": [],
   "source": [
    "use_cuda=True\n",
    "device = torch.device(\"cuda\" if (use_cuda and torch.cuda.is_available()) else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ojfonaxgSvQE"
   },
   "source": [
    "##Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J-WKoIKbEYk1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(Net, self).__init__()\n",
    "    self.conv1 = nn.Conv2d(1, 32, 3, padding=1)\n",
    "    self.conv2 = nn.Conv2d(32, 32, 3, padding=1)\n",
    "    self.conv3 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "    self.conv4 = nn.Conv2d(64, 64, 3, padding=1)\n",
    "    \n",
    "    self.fc1 = nn.Linear(3136, 200)\n",
    "    self.dropout1 = nn.Dropout(0.5)\n",
    "    self.fc2 = nn.Linear(200, 200)\n",
    "    self.dropout2 = nn.Dropout(0.5)\n",
    "    self.fc3 = nn.Linear(200, 10)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = F.relu(self.conv1(x))\n",
    "    x = F.relu(self.conv2(x))\n",
    "    x = F.max_pool2d(x, 2, 2)\n",
    "    x = F.relu(self.conv3(x))\n",
    "    x = F.relu(self.conv4(x))\n",
    "    x = F.max_pool2d(x, 2, 2)\n",
    "    #print(x.shape)\n",
    "    #x = torch.flatten(x, 1)\n",
    "    x = x.view(-1, 7*7*64) # Flattens to 1x7*7*64 row vector\n",
    "    x = F.relu(self.fc1(x))\n",
    "    x = self.dropout1(x)\n",
    "    x = F.relu(self.fc2(x))\n",
    "    x = self.dropout1(x)\n",
    "    x = self.fc3(x)\n",
    "    x = F.log_softmax(x, dim=1)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jUN6hEiBErhm",
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Net().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AptkqWI9YljT",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#optimizer = optim.Adam(model.parameters(),lr=0.0001, betas=(0.9, 0.999))\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.5, nesterov=True)\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "#scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yiX8fKnhYMu4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fit(model,device,train_loader,val_loader,epochs):\n",
    "  data_loader = {'train':train_loader,'val':val_loader}\n",
    "  print(\"Fitting the model...\")\n",
    "  train_loss,val_loss=[],[]\n",
    "  for epoch in range(epochs):\n",
    "    loss_per_epoch,val_loss_per_epoch=0,0\n",
    "    for phase in ('train','val'):\n",
    "      for i,data in enumerate(data_loader[phase]):\n",
    "        input,label  = data[0].to(device),data[1].to(device)\n",
    "        output = model(input)\n",
    "        #calculating loss on the output\n",
    "        loss = criterion(output,label.long())\n",
    "        if phase == 'train':\n",
    "          optimizer.zero_grad()\n",
    "          #grad calc w.r.t Loss func\n",
    "          loss.backward()\n",
    "          #update weights\n",
    "          optimizer.step()\n",
    "          loss_per_epoch+=loss.item()\n",
    "        else:\n",
    "          val_loss_per_epoch+=loss.item()\n",
    "    #scheduler.step(val_loss_per_epoch/len(val_loader))\n",
    "    print(\"Epoch: {} Loss: {} Val_Loss: {}\".format(epoch+1,loss_per_epoch/len(train_loader),val_loss_per_epoch/len(val_loader)))\n",
    "    train_loss.append(loss_per_epoch/len(train_loader))\n",
    "    val_loss.append(val_loss_per_epoch/len(val_loader))\n",
    "  return train_loss,val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_save(model,devide,train_loader,val_loader,epochs,retrain):\n",
    "    file_path = \"./model/Exp1_MNIST.pth\"\n",
    "    if(retrain == True or not(os.path.exists(file_path))):\n",
    "        loss,val_loss=fit(model,device,train_loader,val_loader,epochs)\n",
    "        torch.save(model.state_dict(), file_path)\n",
    "        np.save('./model/Exp1_MNIST_loss_array.npy', loss)\n",
    "        np.save('./model/Exp1_MNIST_val_loss_array.npy', val_loss)\n",
    "    else:\n",
    "        model.load_state_dict(torch.load(file_path))\n",
    "        loss = np.load('./model/Exp1_MNIST_loss_array.npy')\n",
    "        val_loss = np.load('./model/Exp1_MNIST_val_loss_array.npy')\n",
    "    return loss,val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "KZsY1KfZjELB",
    "outputId": "79bfe15d-c7d5-45ff-f2aa-129eed6535dc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss,val_loss=fit_and_save(model,device,train_loader,val_loader,50,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 334
    },
    "colab_type": "code",
    "id": "jIn4g_o7NnXH",
    "outputId": "ffe81618-de62-49ca-adab-d637e99a9693",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(5,5))\n",
    "plt.plot(np.arange(1,51), loss, \"*-\",label=\"Loss\")\n",
    "plt.plot(np.arange(1,51), val_loss,\"o-\",label=\"Val Loss\")\n",
    "plt.xlabel(\"Num of epochs\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HC02Gxez9-21",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fgsm_attack(input,epsilon,data_grad):\n",
    "  pert_out = input + epsilon*data_grad.sign()\n",
    "  pert_out = torch.clamp(pert_out, 0, 1)\n",
    "  return pert_out\n",
    "\n",
    "def mifgsm_attack(input,epsilon,data_grad):\n",
    "  iter=10\n",
    "  decay_factor=1.0\n",
    "  pert_out = input\n",
    "  alpha = epsilon/iter\n",
    "  g=0\n",
    "  for i in range(iter-1):\n",
    "    g = decay_factor*g + data_grad/torch.norm(data_grad,p=1)\n",
    "    pert_out = pert_out + alpha*torch.sign(g)\n",
    "    pert_out = torch.clamp(pert_out, 0, 1)\n",
    "    if torch.norm((pert_out-input),p=float('inf')) > epsilon:\n",
    "      break\n",
    "  return pert_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deepfool_attack(image, net, num_classes=10, overshoot = 0.02, max_iter=10):\n",
    "\n",
    "    \"\"\"\n",
    "       :param image: Image of size HxWx3\n",
    "       :param net: network (input: images, output: values of activation **BEFORE** softmax).\n",
    "       :param num_classes: num_classes (limits the number of classes to test against, by default = 10)\n",
    "       :param overshoot: used as a termination criterion to prevent vanishing updates (default = 0.02).\n",
    "       :param max_iter: maximum number of iterations for deepfool (default = 50)\n",
    "       :return: minimal perturbation that fools the classifier, number of iterations that it required, new estimated_label and perturbed image\n",
    "    \"\"\"\n",
    "    is_cuda = torch.cuda.is_available()\n",
    "\n",
    "    if is_cuda:\n",
    "        #print(\"Using GPU\")\n",
    "        image = image.cuda()\n",
    "        net = net.cuda()\n",
    "    else:\n",
    "        print(\"Using CPU\")\n",
    "\n",
    "\n",
    "    f_image = net.forward(Variable(image, requires_grad=True)).data.cpu().numpy().flatten()\n",
    "    I = (np.array(f_image)).flatten().argsort()[::-1]\n",
    "\n",
    "    I = I[0:num_classes]\n",
    "    label = I[0]\n",
    "\n",
    "    input_shape = image.cpu().detach().numpy().shape\n",
    "    pert_image = copy.deepcopy(image)\n",
    "    w = np.zeros(input_shape)\n",
    "    r_tot = np.zeros(input_shape)\n",
    "\n",
    "    loop_i = 0\n",
    "\n",
    "    x = Variable(pert_image, requires_grad=True)\n",
    "    fs = net.forward(x)\n",
    "    fs_list = [fs[0,I[k]] for k in range(num_classes)]\n",
    "    k_i = label\n",
    "\n",
    "    while k_i == label and loop_i < max_iter:\n",
    "\n",
    "        pert = np.inf\n",
    "        fs[0, I[0]].backward(retain_graph=True)\n",
    "        grad_orig = x.grad.data.cpu().numpy().copy()\n",
    "\n",
    "        for k in range(1, num_classes):\n",
    "            zero_gradients(x)\n",
    "\n",
    "            fs[0, I[k]].backward(retain_graph=True)\n",
    "            cur_grad = x.grad.data.cpu().numpy().copy()\n",
    "\n",
    "            # set new w_k and new f_k\n",
    "            w_k = cur_grad - grad_orig\n",
    "            f_k = (fs[0, I[k]] - fs[0, I[0]]).data.cpu().numpy()\n",
    "\n",
    "            pert_k = abs(f_k)/np.linalg.norm(w_k.flatten())\n",
    "\n",
    "            # determine which w_k to use\n",
    "            if pert_k < pert:\n",
    "                pert = pert_k\n",
    "                w = w_k\n",
    "\n",
    "        # compute r_i and r_tot\n",
    "        # Added 1e-4 for numerical stability\n",
    "        r_i =  (pert+1e-4) * w / np.linalg.norm(w)\n",
    "        r_tot = np.float32(r_tot + r_i)\n",
    "\n",
    "        if is_cuda:\n",
    "            pert_image = image + (1+overshoot)*torch.from_numpy(r_tot).cuda()\n",
    "        else:\n",
    "            pert_image = image + (1+overshoot)*torch.from_numpy(r_tot)\n",
    "\n",
    "        x = Variable(pert_image, requires_grad=True)\n",
    "        fs = net.forward(x)\n",
    "        k_i = np.argmax(fs.data.cpu().numpy().flatten())\n",
    "\n",
    "        loop_i += 1\n",
    "\n",
    "    r_tot = (1+overshoot)*r_tot\n",
    "\n",
    "    return pert_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flow_st(images,flows):\n",
    "  images_shape = images.size()\n",
    "  flows_shape = flows.size()\n",
    "  batch_size = images_shape[0]\n",
    "  H = images_shape[2]\n",
    "  W = images_shape[3]\n",
    "  basegrid = torch.stack(torch.meshgrid(torch.arange(0,H), torch.arange(0,W))) #(2,H,W)\n",
    "  sampling_grid = basegrid.unsqueeze(0).type(torch.float32).cuda() + flows.cuda()\n",
    "  sampling_grid_x = torch.clamp(sampling_grid[:,1],0.0,W-1.0).type(torch.float32)\n",
    "  sampling_grid_y = torch.clamp(sampling_grid[:,0],0.0,H-1.0).type(torch.float32)\n",
    "\n",
    "  x0 = torch.floor(sampling_grid_x).type(torch.int64)\n",
    "  x1 = x0 + 1\n",
    "  y0 = torch.floor(sampling_grid_y).type(torch.int64)\n",
    "  y1 = y0 + 1\n",
    "\n",
    "  x0 = torch.clamp(x0, 0, W - 2)\n",
    "  x1 = torch.clamp(x1, 0, W - 1)\n",
    "  y0 = torch.clamp(y0, 0, H - 2)\n",
    "  y1 = torch.clamp(y1, 0, H - 1)\n",
    "  \n",
    "  Ia = images[:,:,y0[0,:,:], x0[0,:,:]]\n",
    "  Ib = images[:,:,y1[0,:,:], x0[0,:,:]]\n",
    "  Ic = images[:,:,y0[0,:,:], x1[0,:,:]]\n",
    "  Id = images[:,:,y1[0,:,:], x1[0,:,:]]\n",
    "\n",
    "  x0 = x0.type(torch.float32)\n",
    "  x1 = x1.type(torch.float32)\n",
    "  y0 = y0.type(torch.float32)\n",
    "  y1 = y1.type(torch.float32)\n",
    "  \n",
    "  wa = (x1 - sampling_grid_x) * (y1 - sampling_grid_y)\n",
    "  wb = (x1 - sampling_grid_x) * (sampling_grid_y - y0)\n",
    "  wc = (sampling_grid_x - x0) * (y1 - sampling_grid_y)\n",
    "  wd = (sampling_grid_x - x0) * (sampling_grid_y - y0)\n",
    "  \n",
    "  perturbed_image = wa.unsqueeze(0)*Ia+wb.unsqueeze(0)*Ib+wc.unsqueeze(0)*Ic+wd.unsqueeze(0)*Id\n",
    "\n",
    "  return perturbed_image.type(torch.float32).cuda()\n",
    "\n",
    "def flow_loss(flows,padding_mode='constant', epsilon=1e-8):\n",
    "  paddings = (1,1,1,1)\n",
    "  padded_flows = F.pad(flows,paddings,mode=padding_mode,value=0)\n",
    "  shifted_flows = [\n",
    "    padded_flows[:, :, 2:, 2:],  # bottom right (+1,+1)\n",
    "    padded_flows[:, :, 2:, :-2],  # bottom left (+1,-1)\n",
    "    padded_flows[:, :, :-2, 2:],  # top right (-1,+1)\n",
    "    padded_flows[:, :, :-2, :-2]  # top left (-1,-1)\n",
    "  ]\n",
    "  #||\\Delta u^{(p)} - \\Delta u^{(q)}||_2^2 + # ||\\Delta v^{(p)} - \\Delta v^{(q)}||_2^2 \n",
    "  loss=0\n",
    "  for shifted_flow in shifted_flows:\n",
    "    loss += torch.sum(torch.square(flows[:, 1] - shifted_flow[:, 1]) + torch.square(flows[:, 0] - shifted_flow[:, 0]) + epsilon).cuda()\n",
    "  return loss.type(torch.float32)\n",
    "\n",
    "def adv_loss(logits,targets,confidence=0.0):\n",
    "  confidence=torch.tensor(confidence).cuda()\n",
    "  real = torch.sum(logits*targets,-1)\n",
    "  other = torch.max((1-targets)*logits-(targets*10000),-1)[0]\n",
    "  return torch.max(other-real,confidence)[0].type(torch.float32)\n",
    "\n",
    "def func(flows,input,target,model,const=0.05):\n",
    "  input = torch.from_numpy(input).cuda()\n",
    "  target = torch.from_numpy(target).cuda()\n",
    "  flows = torch.from_numpy(flows).view((1,2,)+input.size()[2:]).cuda()\n",
    "  flows.requires_grad=True\n",
    "  pert_out = flow_st(input,flows)\n",
    "  output = model(pert_out)\n",
    "  L_flow = flow_loss(flows)\n",
    "  L_adv = adv_loss(output,target)\n",
    "  L_final = L_adv+const*L_flow\n",
    "  model.zero_grad()\n",
    "  L_final.backward()\n",
    "  gradient = flows.grad.data.view(-1).detach().cpu().numpy()\n",
    "  return L_final.item(),gradient\n",
    "\n",
    "def spatial_attack(input,model,target):\n",
    "  init_flows = np.zeros((1,2,)+input.size()[2:]).reshape(-1)\n",
    "  results = optimize.fmin_l_bfgs_b(func,init_flows,args=(input.cpu().detach().numpy(),target.cpu().detach().numpy(),model))\n",
    "  if b'CONVERGENCE' in results[2]['task']:\n",
    "    flows = torch.from_numpy(results[0]).view((1,2,)+input.size()[2:])\n",
    "    pert_out = flow_st(input,flows)\n",
    "  else:\n",
    "    return None\n",
    "  return pert_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test_model(model,device,test_loader):\n",
    "    correct = 0\n",
    "    for data, target in test_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = model(data)\n",
    "        init_pred = output.max(1, keepdim=True)[1]\n",
    "        if init_pred.item() == target.item():\n",
    "            correct += 1\n",
    "            \n",
    "    final_acc = correct/float(len(test_loader))\n",
    "    print(\"Test Accuracy = {} / {} = {}\".format(correct, len(test_loader), final_acc))\n",
    "    \n",
    "#test_model(model, device,test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class AugmentedDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        # convert into PyTorch tensors and remember them\n",
    "        self.X = X\n",
    "        self.y = y\n",
    " \n",
    "    def __len__(self):\n",
    "        # this should return the size of the dataset\n",
    "        return len(self.X)\n",
    " \n",
    "    def __getitem__(self, idx):\n",
    "        # this should return one sample from the dataset\n",
    "        features = self.X[idx]\n",
    "        target = self.y[idx]\n",
    "        return features, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def CreateTestDataset(model,device,loader,hyperparameter,attack):\n",
    "  correct = 0\n",
    "  X = []\n",
    "  y = []\n",
    "  i = 0\n",
    "  for data, target in test_loader:\n",
    "      if(i % 250 == 0):\n",
    "        print(i/len(test_loader))\n",
    "      i += 1\n",
    "      data, target = data.to(device), target.to(device)\n",
    "      data.requires_grad = True\n",
    "      output = model(data)\n",
    "      loss = F.nll_loss(output, target)\n",
    "      model.zero_grad()\n",
    "      loss.backward()\n",
    "      data_grad = data.grad.data\n",
    "\n",
    "      if attack == \"fgsm\":\n",
    "        perturbed_data = fgsm_attack(data,hyperparameter,data_grad)\n",
    "      elif attack == \"mifgsm\":\n",
    "        perturbed_data = mifgsm_attack(data,hyperparameter,data_grad)\n",
    "      elif attack == \"deepfool\":\n",
    "        perturbed_data = deepfool_attack(data, model)\n",
    "      elif attack == \"spatial\":\n",
    "        random_target = hyperparameter\n",
    "        attack_target = torch.from_numpy(np.expand_dims(np.eye(10, dtype=np.float32)[random_target],0)).cuda()\n",
    "        perturbed_data = spatial_attack(data, model,attack_target)\n",
    "    \n",
    "      X.append(perturbed_data[0])\n",
    "      y.append(target.item())\n",
    "\n",
    "  return AugmentedDataset(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.025\n",
      "0.05\n",
      "0.075\n",
      "0.1\n",
      "0.125\n",
      "0.15\n",
      "0.175\n",
      "0.2\n",
      "0.225\n",
      "0.25\n",
      "0.275\n",
      "0.3\n",
      "0.325\n",
      "0.35\n",
      "0.375\n",
      "0.4\n",
      "0.425\n",
      "0.45\n",
      "0.475\n",
      "0.5\n",
      "0.525\n",
      "0.55\n",
      "0.575\n",
      "0.6\n",
      "0.625\n",
      "0.65\n",
      "0.675\n",
      "0.7\n",
      "0.725\n",
      "0.75\n",
      "0.775\n",
      "0.8\n",
      "0.825\n",
      "0.85\n",
      "0.875\n",
      "0.9\n",
      "0.925\n",
      "0.95\n",
      "0.975\n",
      "spatial created\n",
      "0.0\n",
      "0.025\n",
      "0.05\n",
      "0.075\n",
      "0.1\n",
      "0.125\n",
      "0.15\n",
      "0.175\n",
      "0.2\n",
      "0.225\n",
      "0.25\n",
      "0.275\n",
      "0.3\n",
      "0.325\n",
      "0.35\n",
      "0.375\n",
      "0.4\n",
      "0.425\n",
      "0.45\n",
      "0.475\n",
      "0.5\n",
      "0.525\n",
      "0.55\n",
      "0.575\n",
      "0.6\n",
      "0.625\n",
      "0.65\n",
      "0.675\n",
      "0.7\n",
      "0.725\n",
      "0.75\n",
      "0.775\n",
      "0.8\n",
      "0.825\n",
      "0.85\n",
      "0.875\n",
      "0.9\n",
      "0.925\n",
      "0.95\n",
      "0.975\n",
      "spatial created\n"
     ]
    }
   ],
   "source": [
    "#fgsm_007_test = CreateTestDataset(model, device, test_loader, 0.007, \"fgsm\")\n",
    "#print(\"fgsm 0.007 created\")\n",
    "#fgsm_01_test = CreateTestDataset(model, device, test_loader, 0.01, \"fgsm\")\n",
    "#print(\"fgsm 0.01 created\")\n",
    "#fgsm_02_test = CreateTestDataset(model, device, test_loader, 0.02, \"fgsm\")\n",
    "#print(\"fgsm 0.02 created\")\n",
    "#fgsm_03_test = CreateTestDataset(model, device, test_loader, 0.03, \"fgsm\")\n",
    "#print(\"fgsm 0.03 created\")\n",
    "#fgsm_05_test = CreateTestDataset(model, device, test_loader, 0.05, \"fgsm\")\n",
    "#print(\"fgsm 0.05 created\")\n",
    "#fgsm_1_test = CreateTestDataset(model, device, test_loader, 0.1, \"fgsm\")\n",
    "#print(\"fgsm 0.1 created\")\n",
    "#fgsm_2_test = CreateTestDataset(model, device, test_loader, 0.2, \"fgsm\")\n",
    "#print(\"fgsm 0.2 created\")\n",
    "#fgsm_3_test = CreateTestDataset(model, device, test_loader, 0.3, \"fgsm\")\n",
    "#print(\"fgsm 0.3 created\")\n",
    "\n",
    "#mifgsm_007_test = CreateTestDataset(model, device, test_loader, 0.007, \"mifgsm\")\n",
    "#print(\"mifgsm 0.007 created\")\n",
    "#mifgsm_01_test = CreateTestDataset(model, device, test_loader, 0.01, \"mifgsm\")\n",
    "#print(\"mifgsm 0.01 created\")\n",
    "#mifgsm_02_test = CreateTestDataset(model, device, test_loader, 0.02, \"mifgsm\")\n",
    "#print(\"mifgsm 0.02 created\")\n",
    "#mifgsm_03_test = CreateTestDataset(model, device, test_loader, 0.03, \"mifgsm\")\n",
    "#print(\"mifgsm 0.03 created\")\n",
    "#mifgsm_05_test = CreateTestDataset(model, device, test_loader, 0.05, \"mifgsm\")\n",
    "#print(\"mifgsm 0.05 created\")\n",
    "#mifgsm_1_test = CreateTestDataset(model, device, test_loader, 0.1, \"mifgsm\")\n",
    "#print(\"mifgsm 0.1 created\")\n",
    "#mifgsm_2_test = CreateTestDataset(model, device, test_loader, 0.2, \"mifgsm\")\n",
    "#print(\"mifgsm 0.2 created\")\n",
    "#mifgsm_3_test = CreateTestDataset(model, device, test_loader, 0.3, \"mifgsm\")\n",
    "#print(\"mifgsm 0.3 created\")\n",
    "\n",
    "#deepfool_test = CreateTestDataset(model, device, test_loader, 0, \"deepfool\")\n",
    "#print(\"deepfool created\")\n",
    "\n",
    "#spatial_0_test = CreateTestDataset(model, device, test_loader, 0, \"spatial\")\n",
    "#print(\"spatial created\")\n",
    "#spatial_1_test = CreateTestDataset(model, device, test_loader, 1, \"spatial\")\n",
    "#print(\"spatial created\")\n",
    "#spatial_2_test = CreateTestDataset(model, device, test_loader, 2, \"spatial\")\n",
    "#print(\"spatial created\")\n",
    "#spatial_3_test = CreateTestDataset(model, device, test_loader, 3, \"spatial\")\n",
    "#print(\"spatial created\")\n",
    "#spatial_4_test = CreateTestDataset(model, device, test_loader, 4, \"spatial\")\n",
    "#print(\"spatial created\")\n",
    "#spatial_5_test = CreateTestDataset(model, device, test_loader, 5, \"spatial\")\n",
    "#print(\"spatial created\")\n",
    "#spatial_6_test = CreateTestDataset(model, device, test_loader, 6, \"spatial\")\n",
    "#print(\"spatial created\")\n",
    "#spatial_7_test = CreateTestDataset(model, device, test_loader, 7, \"spatial\")\n",
    "#print(\"spatial created\")\n",
    "spatial_8_test = CreateTestDataset(model, device, test_loader, 8, \"spatial\")\n",
    "print(\"spatial created\")\n",
    "spatial_9_test = CreateTestDataset(model, device, test_loader, 9, \"spatial\")\n",
    "print(\"spatial created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#torch.save(fgsm_007_test,'./custom_datasets/MNIST_fgsm_007_test.pth')\n",
    "#torch.save(fgsm_01_test,'./custom_datasets/MNIST_fgsm_01_test.pth')\n",
    "#torch.save(fgsm_02_test,'./custom_datasets/MNIST_fgsm_02_test.pth')\n",
    "#torch.save(fgsm_03_test,'./custom_datasets/MNIST_fgsm_03_test.pth')\n",
    "#torch.save(fgsm_05_test,'./custom_datasets/MNIST_fgsm_05_test.pth')\n",
    "#torch.save(fgsm_1_test,'./custom_datasets/MNIST_fgsm_1_test.pth')\n",
    "#torch.save(fgsm_2_test,'./custom_datasets/MNIST_fgsm_2_test.pth')\n",
    "#torch.save(fgsm_3_test,'./custom_datasets/MNIST_fgsm_3_test.pth')\n",
    "\n",
    "#torch.save(mifgsm_007_test,'./custom_datasets/MNIST_mifgsm_007_test.pth')\n",
    "#torch.save(mifgsm_01_test,'./custom_datasets/MNIST_mifgsm_01_test.pth')\n",
    "#torch.save(mifgsm_02_test,'./custom_datasets/MNIST_mifgsm_02_test.pth')\n",
    "#torch.save(mifgsm_03_test,'./custom_datasets/MNIST_mifgsm_03_test.pth')\n",
    "#torch.save(mifgsm_05_test,'./custom_datasets/MNIST_mifgsm_05_test.pth')\n",
    "#torch.save(mifgsm_1_test,'./custom_datasets/MNIST_mifgsm_1_test.pth')\n",
    "#torch.save(mifgsm_2_test,'./custom_datasets/MNIST_mifgsm_2_test.pth')\n",
    "#torch.save(mifgsm_3_test,'./custom_datasets/MNIST_mifgsm_3_test.pth')\n",
    "\n",
    "#torch.save(deepfool_test,'./custom_datasets/MNIST_deepfool_test.pth')\n",
    "\n",
    "#torch.save(spatial_0_test,'./custom_datasets/MNIST_spatial_0_test.pth')\n",
    "#torch.save(spatial_1_test,'./custom_datasets/MNIST_spatial_1_test.pth')\n",
    "#torch.save(spatial_2_test,'./custom_datasets/MNIST_spatial_2_test.pth')\n",
    "#torch.save(spatial_3_test,'./custom_datasets/MNIST_spatial_3_test.pth')\n",
    "#torch.save(spatial_4_test,'./custom_datasets/MNIST_spatial_4_test.pth')\n",
    "#torch.save(spatial_5_test,'./custom_datasets/MNIST_spatial_5_test.pth')\n",
    "#torch.save(spatial_6_test,'./custom_datasets/MNIST_spatial_6_test.pth')\n",
    "#torch.save(spatial_7_test,'./custom_datasets/MNIST_spatial_7_test.pth')\n",
    "torch.save(spatial_8_test,'./custom_datasets/MNIST_spatial_8_test.pth')\n",
    "torch.save(spatial_9_test,'./custom_datasets/MNIST_spatial_9_test.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 2.3374e-07, 1.7952e-07, 2.3374e-07,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 4.3009e-08, 0.0000e+00,\n",
      "          0.0000e+00, 4.0392e-01, 4.9019e-01, 7.5294e-01, 4.9019e-01,\n",
      "          3.9215e-01, 2.5431e-07, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 1.8039e-01, 6.4705e-01,\n",
      "          9.7647e-01, 9.9608e-01, 9.9608e-01, 1.0000e+00, 9.9608e-01,\n",
      "          9.9216e-01, 5.3333e-01, 4.5664e-06, 7.4798e-08, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 6.1176e-01, 9.9608e-01,\n",
      "          9.9608e-01, 9.9608e-01, 7.7255e-01, 9.9608e-01, 9.9608e-01,\n",
      "          9.9608e-01, 9.8824e-01, 8.7059e-01, 1.5687e-01, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 6.3578e-08, 6.6671e-02, 5.2157e-01,\n",
      "          4.1569e-01, 7.4511e-02, 3.5295e-02, 7.4520e-02, 7.6471e-01,\n",
      "          9.9608e-01, 9.9608e-01, 9.9608e-01, 8.3137e-01, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 7.1058e-08, 7.4511e-02,\n",
      "          5.4902e-01, 9.9607e-01, 9.9608e-01, 9.8431e-01, 5.4118e-01,\n",
      "          2.1317e-07, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          2.7451e-02, 5.4509e-01, 9.9608e-01, 9.9608e-01, 9.3333e-01,\n",
      "          1.4902e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 2.7455e-02, 7.1765e-01, 9.9608e-01, 9.9608e-01,\n",
      "          4.0785e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 4.7123e-07, 2.4707e-01, 9.9608e-01, 9.9608e-01,\n",
      "          5.6471e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 1.5686e-01, 9.9608e-01, 9.9608e-01,\n",
      "          9.2157e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 1.5686e-01, 9.9608e-01, 9.9608e-01,\n",
      "          9.2156e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 7.3302e-07, 1.5857e-06, 2.2484e-05,\n",
      "          2.4085e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.0644e-06,\n",
      "          9.9182e-06, 1.5895e-06, 1.5687e-01, 9.9608e-01, 9.9608e-01,\n",
      "          6.5490e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          3.2911e-07, 1.3890e-05, 1.9217e-01, 2.0787e-01, 6.5491e-01,\n",
      "          7.2157e-01, 7.2156e-01, 4.5882e-01, 7.2156e-01, 7.2157e-01,\n",
      "          6.1177e-01, 2.0786e-01, 3.2944e-01, 9.9608e-01, 9.9608e-01,\n",
      "          8.1567e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.0569e-07,\n",
      "          8.6293e-02, 6.7059e-01, 9.7647e-01, 9.9608e-01, 9.9608e-01,\n",
      "          9.9608e-01, 9.9608e-01, 9.9608e-01, 1.0000e+00, 9.9608e-01,\n",
      "          9.9608e-01, 9.9608e-01, 9.9608e-01, 9.9608e-01, 9.8039e-01,\n",
      "          3.3725e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.5776e-06,\n",
      "          4.6666e-01, 9.9608e-01, 9.9608e-01, 9.9608e-01, 9.9607e-01,\n",
      "          9.9608e-01, 9.9608e-01, 9.9608e-01, 9.9608e-01, 9.9608e-01,\n",
      "          9.9608e-01, 9.9608e-01, 9.9608e-01, 9.9608e-01, 9.0980e-01,\n",
      "          6.6667e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 6.3578e-08, 6.6677e-02,\n",
      "          7.9607e-01, 9.9608e-01, 9.9607e-01, 6.8235e-01, 3.5686e-01,\n",
      "          3.5686e-01, 3.5686e-01, 3.5687e-01, 3.5687e-01, 4.7843e-01,\n",
      "          9.6078e-01, 9.9608e-01, 9.9608e-01, 9.9608e-01, 9.9608e-01,\n",
      "          7.3727e-01, 3.7698e-06, 9.7237e-08, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 2.8274e-06, 4.3922e-01,\n",
      "          9.9608e-01, 9.9608e-01, 7.8431e-01, 5.0981e-02, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1033e-06, 2.0002e-01,\n",
      "          8.9020e-01, 9.9608e-01, 9.9608e-01, 9.9608e-01, 1.0000e+00,\n",
      "          9.6863e-01, 3.2943e-01, 5.1000e-02, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          9.3725e-01, 9.9608e-01, 9.9608e-01, 4.3530e-01, 7.8431e-02,\n",
      "          5.4902e-02, 2.7451e-02, 7.8430e-02, 4.7843e-01, 8.9412e-01,\n",
      "          9.9608e-01, 9.9608e-01, 9.8431e-01, 9.2939e-01, 1.0000e+00,\n",
      "          9.9608e-01, 9.9608e-01, 7.6471e-01, 3.9216e-02, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.2261e-07,\n",
      "          4.4314e-01, 9.9608e-01, 9.9608e-01, 9.9608e-01, 9.9608e-01,\n",
      "          8.5490e-01, 6.9804e-01, 9.9608e-01, 9.9608e-01, 9.9608e-01,\n",
      "          9.9608e-01, 8.7059e-01, 3.6863e-01, 5.8828e-02, 7.8038e-01,\n",
      "          9.9608e-01, 9.9608e-01, 9.9606e-01, 4.8625e-01, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          8.3774e-07, 4.3922e-01, 9.3333e-01, 9.8039e-01, 9.9608e-01,\n",
      "          9.9608e-01, 9.9608e-01, 9.9608e-01, 9.9608e-01, 9.9216e-01,\n",
      "          6.0001e-01, 1.4118e-01, 0.0000e+00, 0.0000e+00, 6.0000e-01,\n",
      "          9.7254e-01, 9.7253e-01, 6.9410e-01, 2.2353e-01, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 1.8823e-01, 4.8627e-01,\n",
      "          9.2156e-01, 7.3333e-01, 8.5098e-01, 4.8628e-01, 3.7255e-01,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00]]], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "tensor([[[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 9.1594e-03, 6.3393e-03,\n",
      "          2.6071e-02, 5.1070e-03, 0.0000e+00, 0.0000e+00, 2.0505e-03,\n",
      "          2.4922e-03, 1.0678e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          9.1946e-04, 9.9121e-02, 7.4709e-01, 4.1974e-01, 2.7569e-01,\n",
      "          5.3641e-01, 5.2351e-01, 5.1122e-01, 4.1734e-01, 2.9778e-01,\n",
      "          2.8768e-01, 3.4465e-02, 3.6581e-03, 4.1917e-02, 2.5617e-01,\n",
      "          2.8339e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 1.7477e-01, 8.3199e-01, 9.9607e-01, 9.9388e-01,\n",
      "          8.0264e-01, 7.2459e-01, 6.1599e-01, 7.2287e-01, 9.7855e-01,\n",
      "          9.9051e-01, 6.5190e-01, 5.5592e-01, 8.2253e-01, 9.0255e-01,\n",
      "          7.1800e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 5.2011e-01, 9.9238e-01, 8.5728e-01,\n",
      "          3.2746e-01, 2.8636e-01, 2.7663e-01, 3.3065e-01, 6.0141e-01,\n",
      "          8.7354e-01, 9.9606e-01, 9.9592e-01, 9.9918e-01, 9.6840e-01,\n",
      "          6.7309e-01, 2.0735e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 2.0651e-01, 9.2916e-01, 5.7678e-01,\n",
      "          2.1748e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.4855e-02,\n",
      "          6.3478e-01, 9.9554e-01, 6.2954e-01, 4.2425e-01, 3.2067e-01,\n",
      "          6.8588e-02, 1.8803e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 6.7250e-07, 3.0738e-01, 8.1196e-01, 7.1137e-01,\n",
      "          1.6392e-02, 0.0000e+00, 0.0000e+00, 3.8011e-05, 2.8876e-01,\n",
      "          8.6018e-01, 5.1327e-01, 1.4407e-01, 0.0000e+00, 1.7696e-04,\n",
      "          1.8262e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 4.5366e-01, 8.3824e-01, 9.8308e-01,\n",
      "          5.4545e-02, 1.0618e-03, 2.2522e-06, 8.5071e-02, 5.0731e-01,\n",
      "          9.2858e-01, 5.1270e-01, 3.7772e-03, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 5.2943e-01, 9.3290e-01,\n",
      "          7.0215e-01, 7.0980e-02, 1.8212e-04, 4.0737e-01, 7.9345e-01,\n",
      "          9.3911e-01, 6.1199e-01, 3.1890e-03, 1.2483e-11, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2773e-01, 8.7992e-01,\n",
      "          8.7293e-01, 3.0570e-01, 2.4121e-02, 3.9361e-01, 9.8722e-01,\n",
      "          8.7761e-01, 3.6935e-01, 2.0135e-03, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.4792e-01,\n",
      "          3.6482e-01, 2.2321e-02, 6.6676e-03, 2.8291e-01, 9.3265e-01,\n",
      "          7.5974e-01, 9.1948e-02, 1.3040e-05, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2428e-02,\n",
      "          7.0314e-04, 6.4562e-05, 0.0000e+00, 2.3224e-01, 9.2537e-01,\n",
      "          6.5260e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          1.6951e-04, 0.0000e+00, 0.0000e+00, 1.9217e-01, 8.2862e-01,\n",
      "          2.9211e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          2.0896e-02, 6.8251e-01, 7.9199e-01, 8.7095e-01, 9.9349e-01,\n",
      "          6.3163e-01, 3.2008e-01, 2.7813e-01, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          1.4619e-02, 4.3894e-01, 4.9618e-01, 8.7077e-01, 9.9602e-01,\n",
      "          9.9321e-01, 9.2677e-01, 9.6585e-01, 8.8675e-01, 6.8219e-01,\n",
      "          3.0822e-01, 3.0316e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 5.8993e-03, 4.0227e-01, 9.6390e-01,\n",
      "          6.6193e-01, 2.3043e-01, 5.0984e-01, 9.5224e-01, 9.6763e-01,\n",
      "          7.6508e-01, 1.2538e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 3.9646e-03, 2.3499e-01, 9.5256e-01,\n",
      "          4.4921e-01, 6.0238e-03, 4.6038e-03, 3.0802e-02, 4.1591e-01,\n",
      "          6.4491e-01, 1.2366e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1736e-01, 8.4793e-01,\n",
      "          7.7858e-01, 1.3313e-01, 0.0000e+00, 1.0898e-05, 4.5818e-03,\n",
      "          5.7062e-03, 6.1700e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.3058e-01,\n",
      "          9.3091e-01, 4.6736e-01, 0.0000e+00, 5.3761e-06, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.5428e-02,\n",
      "          7.7969e-01, 8.3206e-01, 2.3842e-01, 4.1888e-03, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2387e-01,\n",
      "          7.1523e-01, 9.7593e-01, 7.3209e-01, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.6280e-02,\n",
      "          6.4019e-01, 9.5792e-01, 5.4600e-01, 6.1078e-02, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.9860e-04,\n",
      "          5.5631e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00]]], device='cuda:0',\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "#fgsm_007_test = torch.load('./custom_datasets/MNIST_fgsm_007_test.pth')\n",
    "#print(mifgsm_3_test.X[0])\n",
    "\n",
    "#deepfool_test = torch.load('./custom_datasets/MNIST_deepfool_test.pth')\n",
    "#print(deepfool_test.X[0])\n",
    "\n",
    "#spatial_0_test = torch.load('./custom_datasets/MNIST_spatial_0_test.pth')\n",
    "#print(spatial_0_test.X[0])\n",
    "#spatial_1_test = torch.load('./custom_datasets/MNIST_spatial_1_test.pth')\n",
    "#print(spatial_1_test.X[0])\n",
    "#spatial_2_test = torch.load('./custom_datasets/MNIST_spatial_2_test.pth')\n",
    "#print(spatial_2_test.X[0])\n",
    "#spatial_3_test = torch.load('./custom_datasets/MNIST_spatial_3_test.pth')\n",
    "#print(spatial_3_test.X[0])\n",
    "#spatial_4_test = torch.load('./custom_datasets/MNIST_spatial_4_test.pth')\n",
    "#print(spatial_4_test.X[0])\n",
    "#spatial_5_test = torch.load('./custom_datasets/MNIST_spatial_5_test.pth')\n",
    "#print(spatial_5_test.X[0])\n",
    "#spatial_6_test = torch.load('./custom_datasets/MNIST_spatial_6_test.pth')\n",
    "#print(spatial_6_test.X[0])\n",
    "#spatial_7_test = torch.load('./custom_datasets/MNIST_spatial_7_test.pth')\n",
    "#print(spatial_7_test.X[0])\n",
    "spatial_8_test = torch.load('./custom_datasets/MNIST_spatial_8_test.pth')\n",
    "print(spatial_8_test.X[0])\n",
    "spatial_9_test = torch.load('./custom_datasets/MNIST_spatial_9_test.pth')\n",
    "print(spatial_9_test.X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy = 8780 / 10000 = 0.878\n",
      "Test Accuracy = 8700 / 10000 = 0.87\n"
     ]
    }
   ],
   "source": [
    "#mifgsm_3_test_loader = torch.utils.data.DataLoader(mifgsm_3_test,batch_size=1,shuffle=True)\n",
    "#test_model(model, device,mifgsm_3_test_loader)\n",
    "\n",
    "#deepfool_test_loader = torch.utils.data.DataLoader(deepfool_test,batch_size=1,shuffle=True)\n",
    "#test_model(model, device,deepfool_test_loader)\n",
    "\n",
    "#spatial_0_test_loader = torch.utils.data.DataLoader(spatial_0_test,batch_size=1,shuffle=True)\n",
    "#test_model(model, device,spatial_0_test_loader)\n",
    "#spatial_1_test_loader = torch.utils.data.DataLoader(spatial_1_test,batch_size=1,shuffle=True)\n",
    "#test_model(model, device,spatial_1_test_loader)\n",
    "#spatial_2_test_loader = torch.utils.data.DataLoader(spatial_2_test,batch_size=1,shuffle=True)\n",
    "#test_model(model, device,spatial_2_test_loader)\n",
    "#spatial_3_test_loader = torch.utils.data.DataLoader(spatial_3_test,batch_size=1,shuffle=True)\n",
    "#test_model(model, device,spatial_3_test_loader)\n",
    "#spatial_4_test_loader = torch.utils.data.DataLoader(spatial_4_test,batch_size=1,shuffle=True)\n",
    "#test_model(model, device,spatial_4_test_loader)\n",
    "#spatial_5_test_loader = torch.utils.data.DataLoader(spatial_5_test,batch_size=1,shuffle=True)\n",
    "#test_model(model, device,spatial_5_test_loader)\n",
    "#spatial_6_test_loader = torch.utils.data.DataLoader(spatial_6_test,batch_size=1,shuffle=True)\n",
    "#test_model(model, device,spatial_6_test_loader)\n",
    "#spatial_7_test_loader = torch.utils.data.DataLoader(spatial_7_test,batch_size=1,shuffle=True)\n",
    "#test_model(model, device,spatial_7_test_loader)\n",
    "spatial_8_test_loader = torch.utils.data.DataLoader(spatial_8_test,batch_size=1,shuffle=True)\n",
    "test_model(model, device,spatial_8_test_loader)\n",
    "spatial_9_test_loader = torch.utils.data.DataLoader(spatial_9_test,batch_size=1,shuffle=True)\n",
    "test_model(model, device,spatial_9_test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOlIlXSQS3wh88lTwvpnKqX",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Adversarial Example (Attack and defense).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "virEnv",
   "language": "python",
   "name": "virenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
